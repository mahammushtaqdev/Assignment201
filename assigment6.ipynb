{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMptJ719kFjH1NvrR6PvYTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahammushtaqdev/Assignment201/blob/main/assigment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JszNcjGtYqP3",
        "outputId": "0d7671c8-e2bf-4d36-8dfb-509b63d9c415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#The code installs libraries for integrating Google GenAI with LangChain to build AI-powered applications.\n",
        "!pip install -q -U langchain\n",
        "!pip install -q -U google-genai\n",
        "!pip install -q -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "8B0qZKVsY_cv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing ChatGoogleGenerativeAI to interact with Google GenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# Importing Content and Part to handle text content and parts for GenAI\n",
        "from google.genai.types import Content , Part\n",
        "# Importing Markdown and display to show results in Jupyter notebooks\n",
        "from IPython.display import Markdown,display"
      ],
      "metadata": {
        "id": "vg59-9ASbDnB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ChatGoogleGenerativeAI with the specified model and settings\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.0-flash-exp\",  # The specific AI model to use\n",
        "    api_key = userdata.get(\"GOOGLE_API_KEY\"),  # API key for authentication\n",
        "    temperature = 0.5  # Controls randomness in AI responses (0.0 to 1.0)\n",
        ")"
      ],
      "metadata": {
        "id": "4HF-r6ztbgDp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Go to the left sidebar > Files > Upload a file\n",
        "\n",
        "# Step 2: Specify the direct path of the uploaded video\n",
        "video_file_path = \"/content/video.mp4\"  #uploaded the video from local storage.\n",
        "\n",
        "# Step 3: Use the file path\n",
        "print(f\"The video file is accessible at: {video_file_path}\")\n",
        "\n",
        "# Example of accessing the file for further processing\n",
        "# (You can replace this with your video processing code)\n",
        "with open(video_file_path, \"rb\") as video_file:\n",
        "    print(f\"File {video_file_path} is ready for processing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5iTKBVibuqc",
        "outputId": "21cf0c27-afe2-45b6-a756-1d97b30a68ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The video file is accessible at: /content/video.mp4\n",
            "File /content/video.mp4 is ready for processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function uploads a video to Google GenAI and waits for it to finish processing\n",
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "video_file_path = \"/content/video.mp4\"\n",
        "\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(path = video_file_name)\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "    print(\"Video Is Being Processed , Kindly Wait!\")\n",
        "    time.sleep(10)\n",
        "    video_file = client.files.get(name = video_file.name or \"\")\n",
        "  if video_file.state == \"SUCCESS\":\n",
        "    pass\n",
        "  elif video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + (video_file.uri or \"\"))\n",
        "  return video_file"
      ],
      "metadata": {
        "id": "DMCpsVkZg-z_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_nature = upload_video(video_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmnHOH6jhZgR",
        "outputId": "dc77623c-26ba-466f-a4a4-6e876755e56c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Is Being Processed , Kindly Wait!\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/hw4lu0vs6irv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_video_with_langchain(video_file):\n",
        "  prompt_template = \"\"\"For every scene in this video, provide descriptive captions\n",
        " summarizing the visuals along with any spoken dialogue enclosed in quotation marks.\n",
        " Include each caption in an object, along with its corresponding timecode within the video. \"\"\"\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents=[\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_uri(\n",
        "                    file_uri=video_file.uri or \"\",\n",
        "                    mime_type=video_file.mime_type or \"\"),\n",
        "            ]),\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[Part(text=prompt_template)]\n",
        "        )\n",
        "    ]\n",
        "  )\n",
        "  print(\"Video Analysis:\")\n",
        "  display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "DRsysqTDhiD2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_1 = video_nature\n",
        "analyze_video_with_langchain(video_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "4RneCmbOh2lH",
        "outputId": "06baa698-69eb-49b6-8bbd-2664bc07ddc1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Analysis:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"timecode\": \"0:00\",\n    \"caption\": \"A leopard and a porcupine are in the center of a road while a car is in the background. Text that reads 'When your ego is bigger than your pain' and 'wild aura' are also displayed.\"\n  },\n {\n    \"timecode\": \"0:01\",\n    \"caption\":\"The leopard makes contact with the porcupine's quills with its paw.\"\n  },\n  {\n  \"timecode\": \"0:02\",\n   \"caption\":\"The leopard is examining its paw.\"\n  },\n    {\n    \"timecode\":\"0:05\",\n    \"caption\": \"The leopard is still looking at its paw.\"\n  },\n    {\n      \"timecode\":\"0:08\",\n      \"caption\": \"The scene changes to black and white while the leopard is trying to remove the quills from its paw.\"\n    },\n    {\n      \"timecode\":\"0:12\",\n       \"caption\":\"The scene shows a closeup view of the leopard's face and the porcupine's back in black and white.\"\n     },\n  {\n    \"timecode\": \"0:14\",\n    \"caption\": \"The video ends with a closeup of the leopard's face in black and white over a black background with the text 'wild aura' and '@THEREALW.METRA' overlaid on top. An Instagram logo is also displayed.\"\n  }\n]\n```"
          },
          "metadata": {}
        }
      ]
    }
  ]
}